{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AJK0921/Anemia.ai/blob/main/Copy_of_FINGERS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je2ksBgMryzz",
        "outputId": "a9f2aab1-0c98-4fcd-90bc-ef4fb4b615c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYf1FyEgRiRN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "f = r\"/content/drive/MyDrive/Fingernails/train/Anemic\"\n",
        "g = r\"/content/drive/MyDrive/Fingernails/train/NonAnemic\"\n",
        "h = r\"/content/drive/MyDrive/Fingernails/test/Anemic\"\n",
        "i = r\"/content/drive/MyDrive/Fingernails/test/NonAnemic\"\n",
        "\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((90,90))\n",
        "    img.save(f_img)\n",
        "\n",
        "for file in os.listdir(g):\n",
        "    g_img = g+\"/\"+file\n",
        "    img = Image.open(g_img)\n",
        "    img = img.resize((90,90))\n",
        "    img.save(g_img)\n",
        "\n",
        "for file in os.listdir(h):\n",
        "    h_img = h+\"/\"+file\n",
        "    img = Image.open(h_img)\n",
        "    img = img.resize((90,90))\n",
        "    img.save(h_img)\n",
        "\n",
        "for file in os.listdir(i):\n",
        "    i_img = i+\"/\"+file\n",
        "    img = Image.open(i_img)\n",
        "    img = img.resize((90,90))\n",
        "    img.save(i_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nWSBmtMdva3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoMTXoTJ2pnh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsHxJCwf6dwR",
        "outputId": "11d41b1f-57d8-43a5-8ae3-d9a14852719d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE = [90, 90]\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/FINAL/TRAIN\"\n",
        "valid_path = \"/content/drive/MyDrive/FINAL/TEST\"\n",
        "\n",
        "inception = InceptionV3(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na9mRvPpfVDD"
      },
      "outputs": [],
      "source": [
        "for layer in inception.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTMPFopJgJ2x"
      },
      "outputs": [],
      "source": [
        "folders = glob(\"/content/drive/MyDrive/FINAL/TRAIN/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPvIsGnsgig0"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(inception.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pajIGdZgonh"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(2, activation = 'sigmoid')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMAVnH0WhAFk"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=inception.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKl1LY3yxv7N"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.legacy.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWDs9FzHyW8K"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB8uf4Qj0iNM",
        "outputId": "998507e9-5d85-409d-d4a0-c0def02cbcd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2709 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "  directory='/content/drive/MyDrive/Fingernails/train',\n",
        "  target_size = (90, 90),\n",
        "  color_mode=\"rgb\",\n",
        "  batch_size = 32,\n",
        "  class_mode = 'categorical',\n",
        "  subset=\"training\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ19z0Ki2lAq",
        "outputId": "da80b81c-1c6e-47fc-9a9a-5dd35eee09d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1569 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Fingernails/test',\n",
        "  target_size = (90, 90),\n",
        "  batch_size = 32,\n",
        "  color_mode = 'rgb',\n",
        "  class_mode = 'categorical',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Dxhd80fMe5L",
        "outputId": "e2af390b-e4a0-440d-e1a0-4ee617a55545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "85/85 [==============================] - 626s 7s/step - loss: 0.7227 - accuracy: 0.5814 - val_loss: 0.6569 - val_accuracy: 0.6068\n",
            "Epoch 2/8\n",
            "85/85 [==============================] - 61s 717ms/step - loss: 0.6738 - accuracy: 0.6128 - val_loss: 0.6616 - val_accuracy: 0.5997\n",
            "Epoch 3/8\n",
            "85/85 [==============================] - 60s 708ms/step - loss: 0.6305 - accuracy: 0.6523 - val_loss: 0.6340 - val_accuracy: 0.6303\n",
            "Epoch 4/8\n",
            "85/85 [==============================] - 59s 689ms/step - loss: 0.6457 - accuracy: 0.6423 - val_loss: 0.6411 - val_accuracy: 0.6125\n",
            "Epoch 5/8\n",
            "85/85 [==============================] - 58s 675ms/step - loss: 0.6342 - accuracy: 0.6441 - val_loss: 0.6421 - val_accuracy: 0.6125\n",
            "Epoch 6/8\n",
            "85/85 [==============================] - 58s 677ms/step - loss: 0.6205 - accuracy: 0.6545 - val_loss: 0.6360 - val_accuracy: 0.6303\n",
            "Epoch 7/8\n",
            "85/85 [==============================] - 58s 683ms/step - loss: 0.6263 - accuracy: 0.6549 - val_loss: 0.6508 - val_accuracy: 0.6227\n",
            "Epoch 8/8\n",
            "85/85 [==============================] - 60s 706ms/step - loss: 0.6314 - accuracy: 0.6508 - val_loss: 0.6386 - val_accuracy: 0.6342\n"
          ]
        }
      ],
      "source": [
        "r = model.fit(\n",
        "  x=training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=8,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),\n",
        "  verbose=1\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}